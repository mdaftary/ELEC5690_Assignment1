{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Problem 2: 3D medical image segmentation**#\n",
        "The dataset is the The Atrial\n",
        "Segmentation Challenge dataset, including 14 training images and 20 test images"
      ],
      "metadata": {
        "id": "T1KpksCxZ7F6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Install Libraries**"
      ],
      "metadata": {
        "id": "uNbTMcvLbBDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmSKEg2GjmLL"
      },
      "outputs": [],
      "source": [
        "!pip install numpy h5py tensorflow keras itk tqdm medpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mount Drive if needed**"
      ],
      "metadata": {
        "id": "JZYz1MaZbo1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YtIxzHW81JRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define the dataloader**"
      ],
      "metadata": {
        "id": "qE_LbTORbunl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import random\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, directory, batch_size=4, crop_size=(112, 112, 80), shuffle=True, random_crop=True):\n",
        "        self.directory = directory\n",
        "        self.batch_size = batch_size\n",
        "        self.crop_size = crop_size\n",
        "        self.shuffle = shuffle\n",
        "        self.images, self.masks = self.load_data()\n",
        "        self.cropped_images, self.cropped_masks = self.crop_images_and_masks()\n",
        "        self.indexes = np.arange(len(self.cropped_images))\n",
        "        self.random_crop = random_crop\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.masks)//self.batch_size +1\n",
        "\n",
        "    def load_data(self):\n",
        "        images = []\n",
        "        masks = []\n",
        "\n",
        "        for filename in os.listdir(self.directory):\n",
        "            if filename.endswith('.h5'):\n",
        "                file_path = os.path.join(self.directory, filename)\n",
        "                with h5py.File(file_path, 'r') as f:\n",
        "                    img_data = np.array(f['image'])  # Load images\n",
        "                    mask_data = np.array(f['label'])   # Load masks\n",
        "\n",
        "                    if img_data.shape[0] != mask_data.shape[0]:\n",
        "                        raise ValueError(f'Mismatched samples in {filename}')\n",
        "\n",
        "                    images.append(img_data)\n",
        "                    masks.append(mask_data)\n",
        "\n",
        "        return images, masks\n",
        "\n",
        "    def crop_images_and_masks(self):\n",
        "        cropped_images = []\n",
        "        cropped_masks = []\n",
        "\n",
        "        for i in range(len(self.images)):\n",
        "            image, mask = self.random_crop(self.images[i], self.masks[i])\n",
        "            cropped_images.append(image)\n",
        "            cropped_masks.append(mask)\n",
        "\n",
        "        return np.array(cropped_images), np.array(cropped_masks)\n",
        "\n",
        "    def random_crop(self, image, mask):\n",
        "        z, y, x = image.shape\n",
        "        cz, cy, cx = self.crop_size\n",
        "        if self.random_crop == True:\n",
        "          # Do random crop for train_loader\n",
        "          start_z = random.randint(0, z - cz)\n",
        "          start_y = random.randint(0, y - cy)\n",
        "          start_x = random.randint(0, x - cx)\n",
        "        else:\n",
        "          # Do fixed middle crop for test loader\n",
        "          start_z = (z - cz) // 2\n",
        "          start_y = (y - cy) // 2\n",
        "          start_x = (x - cx) // 2\n",
        "        cropped_image = image[start_z:start_z + cz, start_y:start_y + cy, start_x:start_x + cx]\n",
        "        cropped_mask = mask[start_z:start_z + cz, start_y:start_y + cy, start_x:start_x + cx]\n",
        "        return cropped_image, cropped_mask\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "        for start in range(0, len(self.cropped_images), self.batch_size):\n",
        "            end = min(start + self.batch_size, len(self.cropped_images))\n",
        "            yield self.cropped_images[self.indexes[start:end]], self.cropped_masks[self.indexes[start:end]]\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# Batch Size is kept to 1 for all train loader to prevent any discrepanices from floating point precision and maintain\n",
        "# consistency among the testing set for all configurations"
      ],
      "metadata": {
        "id": "uf7_LXpeAY3F"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define Model**"
      ],
      "metadata": {
        "id": "u7TIYqIjONaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "def unet_3d(input_size=(112, 112, 80, 1)):\n",
        "    inputs = Input(input_size)\n",
        "    c1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
        "\n",
        "    c2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
        "\n",
        "    c3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling3D((2, 2, 2))(c3)\n",
        "\n",
        "    c4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = MaxPooling3D((2, 2, 2))(c4)\n",
        "\n",
        "    c5 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    u6 = UpSampling3D((2, 2, 2))(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = UpSampling3D((2, 2, 2))(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = UpSampling3D((2, 2, 2))(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = UpSampling3D((2, 2, 2))(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "axrMXCnPy-Ma"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **CONFIGURATION 1**"
      ],
      "metadata": {
        "id": "1HyYXTLZOWHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURATION 1\n",
        "\n",
        "# First Training configuration dataloader\n",
        "train_loader = DataLoader('/content/drive/MyDrive/train', batch_size=4, shuffle=False, random_crop=False)\n",
        "test_loader = DataLoader('/content/drive/MyDrive/test', batch_size=1, shuffle=False, random_crop=False)\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "losses = []\n",
        "# Training loop\n",
        "def train_model(model, data_loader, num_epochs=50):\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        train_loop = tqdm(enumerate(data_loader), total=len(data_loader), leave= False)\n",
        "        for batch_idx, (batch_images, batch_masks) in train_loop:\n",
        "            # Reshape images to add the channel dimension\n",
        "            batch_images = tf.convert_to_tensor(batch_images[..., np.newaxis])  # Shape: (batch_size, cz, cy, cx, 1)\n",
        "            batch_masks = tf.convert_to_tensor(batch_masks[..., np.newaxis])\n",
        "            loss = model.train_on_batch(batch_images, batch_masks)\n",
        "            epoch_losses.append(loss[0])\n",
        "            losses.append(loss[0])\n",
        "            train_loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "            train_loop.set_postfix(loss=loss[0])\n",
        "\n",
        "        avg_loss = np.mean(epoch_losses)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss}')\n",
        "\n",
        "\n",
        "model = unet_3d()\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss= 'binary_crossentropy', metrics=['accuracy'])\n",
        "# Call the training function with the original batch size\n",
        "train_model(model, train_loader, num_epochs=50)"
      ],
      "metadata": {
        "id": "g2tfEU3MAMqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **CONFIGURATION 2 (BEST ONE)**"
      ],
      "metadata": {
        "id": "zM4bZoHwOr4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURATION 2\n",
        "\n",
        "# Second Training configuration\n",
        "train_loader = DataLoader('/content/drive/MyDrive/train', batch_size=2, shuffle=False, random_crop=False)\n",
        "test_loader = DataLoader('/content/drive/MyDrive/test', batch_size=1, shuffle=False, random_crop=False)\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define Dice loss function with @tf.function\n",
        "@tf.function\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "losses = []\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, data_loader, num_epochs=75):\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        train_loop = tqdm(enumerate(data_loader), total=len(data_loader), leave=False)\n",
        "        for batch_idx, (batch_images, batch_masks) in train_loop:\n",
        "            # Reshape images to add the channel dimension\n",
        "            batch_images = batch_images[..., np.newaxis]  # Shape: (batch_size, cz, cy, cx, 1)\n",
        "\n",
        "            # Ensure batch_masks has the same number of channels\n",
        "            batch_masks = batch_masks[..., np.newaxis]  # Shape: (batch_size, cz, cy, cx, 1)\n",
        "            batch_images = tf.convert_to_tensor(batch_images)  # Shape: (batch_size, cz, cy, cx, 1)\n",
        "            batch_masks = tf.convert_to_tensor(batch_masks)\n",
        "\n",
        "            loss = model.train_on_batch(batch_images, batch_masks)\n",
        "            epoch_losses.append(loss[0])\n",
        "            losses.append(loss[0])\n",
        "            train_loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "            train_loop.set_postfix(loss=loss[0])\n",
        "\n",
        "        avg_loss = np.mean(epoch_losses)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss}')\n",
        "\n",
        "# Model compilation\n",
        "model = unet_3d()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss=dice_loss, metrics=['accuracy'])\n",
        "\n",
        "# Call the training function with the original batch size\n",
        "train_model(model, train_loader, num_epochs=75)"
      ],
      "metadata": {
        "id": "uVWF6V2rPb7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **CONFIGURATION 3**"
      ],
      "metadata": {
        "id": "lSpa-lmjOui2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURATION 3\n",
        "\n",
        "# Third Training configuration\n",
        "train_loader = DataLoader('/content/drive/MyDrive/train', batch_size=2, shuffle=False, random_crop=False)\n",
        "test_loader = DataLoader('/content/drive/MyDrive/test', batch_size=1, shuffle=False, random_crop=False)\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy.ndimage import rotate\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define Dice loss function\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Function to perform random rotation\n",
        "def random_rotate(images, masks):\n",
        "    angle = random.uniform(-20, 20)  # Random angle between -20 and 20 degrees\n",
        "    rotated_images = np.array([rotate(image, angle, reshape=False) for image in images])\n",
        "    rotated_masks = np.array([rotate(mask, angle, reshape=False) for mask in masks])\n",
        "    return rotated_images, rotated_masks\n",
        "\n",
        "# Function to perform random flipping\n",
        "def random_flip(images, masks):\n",
        "    if random.random() > 0.5:  # Flip with 50% probability\n",
        "        flipped_images = np.flip(images, axis=2)  # Flip along the depth axis\n",
        "        flipped_masks = np.flip(masks, axis=2)\n",
        "        return flipped_images, flipped_masks\n",
        "    return images, masks\n",
        "losses = []\n",
        "# Update your training loop to use the manual augmentation\n",
        "def train_model_with_manual_augmentation(model, data_loader, num_epochs=50, batch_size=8):\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        train_loop = tqdm(enumerate(data_loader), total=len(data_loader), leave=False)\n",
        "\n",
        "        # Iterate through the data loader\n",
        "        for batch_idx, (batch_images, batch_masks) in train_loop:\n",
        "            # Apply manual augmentations\n",
        "            batch_images, batch_masks = random_rotate(batch_images, batch_masks)\n",
        "            batch_images, batch_masks = random_flip(batch_images, batch_masks)\n",
        "\n",
        "            # Convert to tensors\n",
        "            batch_images_tensor = tf.convert_to_tensor(batch_images, dtype=tf.float32)\n",
        "            batch_masks_tensor = tf.convert_to_tensor(batch_masks, dtype=tf.float32)\n",
        "\n",
        "            # Train on the augmented batch\n",
        "            loss = model.train_on_batch(batch_images[..., np.newaxis], batch_masks[..., np.newaxis])\n",
        "            epoch_losses.append(loss[0])\n",
        "            losses.append(loss[0])\n",
        "            train_loop.set_description(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "            train_loop.set_postfix(loss=loss[0])\n",
        "\n",
        "        avg_loss = np.mean(epoch_losses)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss}')\n",
        "\n",
        "# Call the training function with the new batch size\n",
        "model = unet_3d()\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss=dice_loss, metrics=['accuracy'])\n",
        "train_model_with_manual_augmentation(model, train_loader, num_epochs=75, batch_size=2)"
      ],
      "metadata": {
        "id": "zQo0Z-eN7tTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Plot training loss**"
      ],
      "metadata": {
        "id": "3egk2n74UyAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_index = []\n",
        "val_index = []\n",
        "num_epochs = 75 # Adjust number of epochs as needed\n",
        "\n",
        "train_batch = 7 # Adjust as needed (number of training samples)/(batch_size) = 14/(batch_size) {if decimal then round to the next number}\n",
        "\n",
        "\n",
        "for i in range(1,num_epochs*train_batch + 1):\n",
        "  train_index.append(i)\n",
        "\n",
        "# Create a figure with subplots\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_index, losses, label='Training Loss', color='blue')\n",
        "plt.title('Loss per batch')\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n4OmqHxc_Y7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluation metrics**"
      ],
      "metadata": {
        "id": "t6CafSBxTvu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this if you want to load any saved weights\n",
        "# model = unet_3d()\n",
        "# model.load_weights('/content/model_config2.weights.h5')"
      ],
      "metadata": {
        "id": "bPJmrw8KPce_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import jaccard_score\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "from medpy.metric.binary import assd\n",
        "from medpy.metric.binary import dc, hd95, jc\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    all_predictions = []\n",
        "    all_masks = []\n",
        "    for test_images, test_masks in data_loader:\n",
        "        # Reshape test images for prediction\n",
        "        test_images_reshaped = test_images[..., np.newaxis]  # Add channel dimension\n",
        "\n",
        "        # Make predictions\n",
        "\n",
        "        predictions = model.predict(test_images_reshaped)\n",
        "\n",
        "        # Store predictions and masks\n",
        "        all_predictions.append(predictions)\n",
        "        all_masks.append(test_masks[..., np.newaxis])\n",
        "\n",
        "    # Concatenate all predictions and masks\n",
        "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "    all_predictions = (all_predictions > 0.5).astype(np.uint8)\n",
        "    all_masks = np.concatenate(all_masks, axis=0)\n",
        "\n",
        "    # Calculate metrics\n",
        "    dice_coeff = np.mean([dc(pred,mask) for pred, mask in zip(all_predictions, all_masks)])\n",
        "    # jaccard = jaccard_score(all_masks.flatten(), (all_predictions > 0.5).astype(int).flatten())\n",
        "    jaccard = np.mean([jc(pred, mask) for pred, mask in zip(all_predictions, all_masks)])\n",
        "\n",
        "    # # Calculate ASD and 95HD\n",
        "    asd_list = []\n",
        "    for pred, mask in zip(all_predictions, all_masks):\n",
        "        if np.count_nonzero(pred) == 0 or np.count_nonzero(mask) == 0:\n",
        "            print(\"Skipping empty prediction or mask\")\n",
        "            continue\n",
        "        asd = assd(pred, mask)\n",
        "        asd_list.append(asd)\n",
        "    hd_list = []\n",
        "    for pred, mask in zip(all_predictions, all_masks):\n",
        "        if np.count_nonzero(pred) == 0 or np.count_nonzero(mask) == 0:\n",
        "            print(\"Skipping empty prediction or mask\")\n",
        "            continue\n",
        "        hd = hd95(pred, mask)\n",
        "        hd_list.append(hd)\n",
        "    avg_asd = np.mean(asd_list)\n",
        "    avg_hd = np.mean(hd_list)  # 95% Hausdorff Distance\n",
        "\n",
        "    return dice_coeff, jaccard, avg_asd, avg_hd\n",
        "\n",
        "# Create a DataLoader for test data\n",
        "# test_loader = DataLoader('./datas/test/', batch_size=4)\n",
        "\n",
        "# Evaluate the model using the DataLoader\n",
        "dice_coeff, jaccard, avg_asd, avg_hd = evaluate_model(model, test_loader)\n",
        "\n",
        "# evaluate_model(model, test_loader)\n",
        "print(f'Dice Coefficient: {dice_coeff}, Jaccard Index: {jaccard}, ASD: {avg_asd}, 95HD: {avg_hd}')"
      ],
      "metadata": {
        "id": "7UCSP-qWmJym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Plotting 2D segmentation results**"
      ],
      "metadata": {
        "id": "mYpb-iusWzRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obtain_testing_data(model, data_loader):\n",
        "    all_predictions = []\n",
        "    all_masks = []\n",
        "    all_images = []\n",
        "\n",
        "    for test_images, test_masks in data_loader:\n",
        "        # Reshape test images for prediction\n",
        "        test_images_reshaped = test_images[..., np.newaxis]  # Add channel dimension\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(test_images_reshaped)\n",
        "\n",
        "        # Store predictions and masks\n",
        "        all_predictions.append(predictions)\n",
        "        all_masks.append(test_masks[..., np.newaxis])\n",
        "\n",
        "        all_images.append(test_images_reshaped)\n",
        "\n",
        "    # Concatenate all predictions and masks\n",
        "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "    all_masks = np.concatenate(all_masks, axis=0)\n",
        "    all_images = np.concatenate(all_images, axis=0)\n",
        "    all_predictions = (all_predictions > 0.5).astype(np.uint8)\n",
        "\n",
        "    return all_predictions, np.array(all_masks), np.array(all_images)"
      ],
      "metadata": {
        "id": "hCGPUXBUntVQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, ground_truth, original_images = obtain_testing_data(model, test_loader)"
      ],
      "metadata": {
        "id": "iPjH9tRrsEXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All of them should (20, 112, 112, 80, 1)\n",
        "print(predictions.shape)\n",
        "print(ground_truth.shape)\n",
        "print(original_images.shape)"
      ],
      "metadata": {
        "id": "ak_HBP-Qsgab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# shapes:\n",
        "# original_images: (num_samples, depth, height, width, channels)\n",
        "# predictions: (num_samples, depth, height, width, channels) with binary masks\n",
        "# ground_truth: (num_samples, depth, height, width, channels) with binary masks\n",
        "\n",
        "# Select the sample (you can change the index to visualize other samples)\n",
        "sample_index = 1\n",
        "original_image = original_images[sample_index]\n",
        "predicted_mask = predictions[sample_index]\n",
        "true_mask = ground_truth[sample_index]\n",
        "\n",
        "# Choose slices to display (e.g., specific slices)\n",
        "\n",
        "slice_indices = [0, 20, 35, 39, 41, 52, 61, 69] # Adjust as needed\n",
        "# for i in range(10):\n",
        "#   slice_indices.append(i+20)\n",
        "# Create a figure for plotting\n",
        "num_slices = len(slice_indices)\n",
        "fig, axs = plt.subplots(num_slices, 4, figsize=(16, 8))\n",
        "\n",
        "for i, slice_index in enumerate(slice_indices):\n",
        "    # Squeeze to remove the last dimension (channels)\n",
        "    original_slice = np.squeeze(original_image[:, :, slice_index, :])\n",
        "    predicted_slice = np.squeeze(predicted_mask[:, :, slice_index, :])\n",
        "    true_slice = np.squeeze(true_mask[:, :, slice_index, :])\n",
        "\n",
        "\n",
        "    # Display the original image slice\n",
        "    axs[i, 0].imshow(original_slice, cmap='gray')\n",
        "    axs[i, 0].set_title(f'Original Image Slice {slice_index}')\n",
        "    axs[i, 0].axis('off')\n",
        "\n",
        "    # Display the predicted mask slice\n",
        "    axs[i, 1].imshow(predicted_slice, cmap='gray')\n",
        "    axs[i, 1].set_title(f'Predicted Mask {slice_index}')\n",
        "    axs[i, 1].axis('off')\n",
        "\n",
        "    # Display the ground truth mask slice\n",
        "    axs[i, 2].imshow(true_slice, cmap='gray')\n",
        "    axs[i, 2].set_title(f'Ground Truth Mask {slice_index}')\n",
        "    axs[i, 2].axis('off')\n",
        "\n",
        "    # Overlay prediction on the original image for comparison\n",
        "    overlay = np.maximum(predicted_slice, true_slice)\n",
        "    axs[i, 3].imshow(overlay, cmap='gray')\n",
        "    axs[i, 3].set_title(f'Overlay Slice {slice_index}')\n",
        "    axs[i, 3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wtXgbeFYoG02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save images, labels, and predictions**"
      ],
      "metadata": {
        "id": "FP5cvjzJXr2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "\n",
        "def save_nifti(image, filename):\n",
        "    img = nib.Nifti1Image(image, np.eye(4))\n",
        "    nib.save(img, filename)\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "  # Change file name and path accordingly\n",
        "  save_nifti(np.squeeze(original_images[i]), f\"/content/drive/MyDrive/results/image{i}.nii.gz\") # Save Image\n",
        "  save_nifti(np.squeeze(ground_truth[i]), f\"/content/drive/MyDrive/results/label{i}.nii.gz\") # Save Prediction\n",
        "  save_nifti(np.squeeze(predictions[i]), f\"/content/drive/MyDrive/results/prediction{i}.nii.gz\") # Save Prediction\n"
      ],
      "metadata": {
        "id": "0B046r4l0sje"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}